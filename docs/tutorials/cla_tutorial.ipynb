{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021051f2",
   "metadata": {},
   "source": [
    "#  Using the pyYeti CLA tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c921645c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Many thanks to **Thomas Weber** for his initial draft of this tutorial!\n",
    "\n",
    "This and other jupyter notebooks are available here: https://github.com/twmacro/pyyeti/tree/master/docs/tutorials.\n",
    "\n",
    "This tutorial will use a simple model to guide through the CLA process using the pyYeti tools. The model is a simple space station model contained in outboard.blk and inboard.blk. The outboard model will be used to create an external superelement, as if this model was delivered as a Craig-Bampton model by an independent group. The inboard model is the core of the residual structure. In the rocket launching business, the outboard model is analogous to a spacecraft model or an upstream component on the rocket, and the inboard model is analogous to the non-upstream part of the launch vehicle model.\n",
    "\n",
    "Outboard:\n",
    "\n",
    "![outboard.png](outboard.png)\n",
    "\n",
    "Inboard:\n",
    "\n",
    "![inboard.png](inboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bd04a",
   "metadata": {},
   "source": [
    "## Outline\n",
    "The general outline for this tutorial is:\n",
    "\n",
    "- Outboard superelement creation\n",
    "- Prepare outboard model for CLA\n",
    "- Run modes on assembled model\n",
    "- Simulate loading events\n",
    "- Summarize results\n",
    "- Compare results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a65351-2ebb-4dff-bba2-43b5f1bdec0a",
   "metadata": {},
   "source": [
    "### Special note about this tutorial\n",
    "In order to speed up the automatic documentation creation step on \"Read the Docs\", a number of lines below are commented out. These all start with `# SPEED:`. These lines all produce output that is not contained within this notebook and would therefore only cost execution time while creating the documentation. However, if you decide to run this tutorial for yourself, it is recommended that these lines be uncommented so you can take a look at all the output. Note that some screenshots of the output is included below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759a2e5",
   "metadata": {},
   "source": [
    "## Nastran runs\n",
    "The outboard model will be used to create an external superelement to simulate a delivery from an independent team. The residual structure run will bring in the outboard model as an external superelement as if we did not have the bulk data. The inboard bulk data is included directly. Both .dat files are shown below for convenience; they exist in the `srcdir` directory that is shown below. These files were run in Siemens Nastran version 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388551bb-091a-44d7-90d3-36d807365ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pyyeti\n",
    "\n",
    "srcdir = Path(inspect.getfile(pyyeti)).parent / \"tests\" / \"cla_test_data_2020\"\n",
    "print(f\"{srcdir = }\")\n",
    "\n",
    "wrkdir = Path.cwd()\n",
    "print(f\"{wrkdir = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab62f7-0711-475f-b907-615a224f7d15",
   "metadata": {},
   "source": [
    "### outboard.dat\n",
    "\n",
    "The following Nastran input file creates the \"outboard\" external superelement (SE 101). This results in 3 files for use in the residual run: outboard.op4, outboard.asm, and outboard.pch.\n",
    "\n",
    "In cases where a Craig-Bampton model is provided but the .op4, .asm, and .pch files are not provided, the routine [pyyeti.nastran.bulk.wtextseout](../modules/nastran/generated/pyyeti.nastran.bulk.wtextseout.html#pyyeti.nastran.bulk.wtextseout) can be used to create these three files. This is typically done in the \"prepare_4_cla.py\" script shown below.\n",
    "\n",
    "File \"outboard.dat\":\n",
    "```text\n",
    "    INIT MASTER(S)  $ delete .MASTER and .DBALL files on exit\n",
    "    ASSIGN OUTPUT4='outboard.op4' UNIT=101,DELETE\n",
    "    SOL 103\n",
    "    CEND\n",
    "    \n",
    "    TITLE = Outboard\n",
    "    ECHO = SORT\n",
    "    WEIGHTCHECK(SET=ALL) = YES\n",
    "    GROUNDCHECK(SET=ALL,DATAREC=YES) = YES\n",
    "    METHOD=1\n",
    "    SET 1 = 1 THRU 48\n",
    "    DISPLACEMENT(PLOT) = 1\n",
    "    FORCE(PLOT) = all\n",
    "    EXTSEOUT(ASMBULK,EXTBULK,EXTID=101,MATOP4=101)\n",
    "    \n",
    "    BEGIN BULK\n",
    "    EIGRL          1            50.0\n",
    "    SPOINT   1995001    THRU 1995022\n",
    "    QSET1            1995001    THRU 1995022\n",
    "    BSET1,123456,3,11,19,27\n",
    "    include 'outboard.blk'\n",
    "    ENDDATA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac09dd3-1117-46db-aaaa-c59ad9e51aa7",
   "metadata": {},
   "source": [
    "### residual.dat\n",
    "\n",
    "Create the residual structure. This file uses inboard.blk and brings in SE 101 via the outboard.op4, outboard.asm and outboard.pch files. This run creates the nas2cam.op2 and nas2cam.op4 files that will be used for analysis in Python.\n",
    "\n",
    "File \"residual.dat\":\n",
    "```text\n",
    "    NASTRAN SYSTEM(402) = 0  $ AUTOMATICALLY DELETE DUPLICATE CARDS\n",
    "    NASTRAN NLINES = 10000\n",
    "    ASSIGN INPUTT4='outboard.op4',UNIT=101\n",
    "    INIT MASTER(S)  $ delete .MASTER and .DBALL files on exit\n",
    "    $ NAS2CAM op2/op4 files:\n",
    "    assign output2 = 'nas2cam.op2', status=new, unit=29,delete $\n",
    "    assign output4 = 'nas2cam.op4', status=new, unit=30,\n",
    "         form=unformatted,delete $\n",
    "    \n",
    "    DIAG    8,47\n",
    "    SOL 111\n",
    "    echooff\n",
    "    include '../nas2cam/nas2cam_111.v9'\n",
    "    include '../nas2cam/nas2cam_subdmap_2023.v9'\n",
    "    \n",
    "    $ bug fix (?) alter for v2020:\n",
    "    COMPILE PHASE0\n",
    "    $ - delete line that prevents RVDOF from being used for resvecs\n",
    "    $ - must also include RESVEC(DYNRSP)=YES if need damping on these resvecs\n",
    "    ALTER 'IF ( NOT(RESVEC0) )'(2),'IF ( NOT(RESVEC0) )'(2) $ DELETE\n",
    "    $ Note: an alternative to RVDOF is to use the older PARAM,RESVEC,YES and\n",
    "    $ USET,U6 approach. That works without this little alter.\n",
    "    ENDALTER $\n",
    "    \n",
    "    echoon\n",
    "    CEND\n",
    "    \n",
    "    TITLE = System Modes\n",
    "    ECHO = Sort\n",
    "    METHOD = 1\n",
    "    FREQ = 1\n",
    "    DLOAD = 1\n",
    "    DISPLACEMENT(PLOT) = ALL\n",
    "    FORCE(PLOT) = ALL\n",
    "    WEIGHTCHECK(SET=ALL) = YES\n",
    "    GROUNDCHECK(SET=ALL,DATAREC=YES) = YES\n",
    "    RESVEC(NOAPPL,RVDOF,NORVEL,NOINRL,NODAMP,NODYNRSP)=YES\n",
    "    \n",
    "    $-------------------------------------------------------------------\n",
    "    $ nas2cam params:\n",
    "    PARAM,PRFMODES,1\n",
    "    $\n",
    "    $ TO GENERATE GRAVITY FORCE, SET GRAVDIR EQUAL TO GRAVITY DIRECTION\n",
    "    $  AND SET THE GRAVITY FIELD:\n",
    "    $\n",
    "    PARAM,GRAVDIR,3\n",
    "    PARAM,GRAVFELD,9806.65  $ mm/sec**2\n",
    "    $-------------------------------------------------------------------\n",
    "    \n",
    "    SUBCASE 1\n",
    "    \tLABEL = Modes run with BHH matrix\n",
    "    \tANALYSIS = MODES\n",
    "    \n",
    "    BEGIN BULK\n",
    "    $-------------------------------------------------------------------\n",
    "    $ NAS2CAM input:\n",
    "    PARAM,DBDICT,0\n",
    "    DTI,TMAA,1,101,0\n",
    "    DTI,TKAA,1,101,0\n",
    "    DTI,TGM,1,0\n",
    "    DTI,TPHG,1,0\n",
    "    DTI,TPHA,1,0\n",
    "    DTI,TBHH,1,0\n",
    "    $-------------------------------------------------------------------\n",
    "    PARAM,POST,-1\n",
    "    PARAM,SESDAMP,YES\n",
    "    EIGRL          1           150.0\n",
    "    $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "    FREQ           1      2.\n",
    "    RLOAD2         1       1                       1\n",
    "    DAREA          1      11       1    1.0\n",
    "    TABLED1        1\n",
    "                0.01     1.0   150.0    1.0     ENDT\n",
    "    $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "    $ for residual flexibility vectors:\n",
    "    RVDOF1,123,8,22,24\n",
    "    INCLUDE 'outboard.asm'\n",
    "    include 'inboard.blk'\n",
    "    INCLUDE 'outboard.pch'\n",
    "    ENDDATA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a32b7",
   "metadata": {},
   "source": [
    "## Prepare Outboard for CLA\n",
    "The prepare_4_cla.py file below prepares the outboard model for CLA. The primary goal is to setup data recovery.\n",
    "\n",
    "This example also runs [pyyeti.cb.cbcheck](../modules/generated/pyyeti.cb.cbcheck.html#pyyeti.cb.cbcheck), though this could be done in a separate model checkout run. This is not discussed further here, but is the subject of a different tutorial: [Using cb.cbcheck to check mass and stiffness](../tutorials/cbcheck.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c48bb-c6e0-4e2e-94c5-e8eede4c3002",
   "metadata": {},
   "source": [
    "### A special data recovery category: \"cglf\"\n",
    "\n",
    "The CG load factor category is special in that row 11 (at Python index 10) is a time-consistent RSS (root-sum-square) of rows 2 and 3. Rows 2 and 3 are the two 90 degrees apart shear-based lateral CG load factors in the SC coordinate system, so row 11 becomes the RSS shear-based lateral load factor. Similarly, row 12 is the RSS of 4 and 5, 13 is the RSS of 7 and 8, and 14 is the RSS of 9 and 10. Together, these rows cover both the shear-based and moment-based lateral CG load factors in the SC and LV coordinate systems. The corresponding RSS values for both coordinate systems should match each other. For PSD (power spectral density) analyses, an analogous RSS is handled with the help of [pyyeti.cla.PSD_consistent_rss](../modules/generated/pyyeti.cla.PSD_consistent_rss.html#pyyeti.cla.PSD_consistent_rss). The data recovery matrix for this category is created by [pyyeti.cb.mk_net_drms](../modules/generated/pyyeti.cb.mk_net_drms.html#pyyeti.cb.mk_net_drms) and the last four rows (11-14) have only zeros.\n",
    "\n",
    "To handle the RSS'ing during data recovery, the file \"dr_file.py\" is created for the \"cglf\" data recovery category with the routines \"cglf\" and \"cglf_psd\". All the other data recovery categories are simple and handled directly in the \"prepare_4_cla.py\" file. See also [pyyeti.cla.DR_Def.add](../modules/edited/pyyeti.cla.DR_Def.add.html#pyyeti.cla.DR_Def.add) for more details on creating data recovery categories.\n",
    "\n",
    "For reference, the contents of \"dr_file.py\" are shown here:\n",
    "```\n",
    "    import numpy as np\n",
    "    from pyyeti import cla\n",
    "    \n",
    "    \n",
    "    def get_xyr():\n",
    "        # return the xr, yr, and rr indexes for the \"cglf\" data recovery\n",
    "        xr = np.array([1, 3, 6, 8])  # 'x' row(s)\n",
    "        yr = xr + 1  # 'y' row(s)\n",
    "        rr = np.arange(4) + 10  # rss  rows\n",
    "        return xr, yr, rr\n",
    "    \n",
    "    \n",
    "    def cglf(sol, nas, Vars, se):\n",
    "        resp = Vars[se][\"cglf\"] @ sol.a\n",
    "        xr, yr, rr = get_xyr()\n",
    "        resp[rr] = np.sqrt(resp[xr] ** 2 + resp[yr] ** 2)\n",
    "        return resp\n",
    "    \n",
    "    \n",
    "    def cglf_psd(sol, nas, Vars, se, freq, forcepsd, drmres, case, i):\n",
    "        resp = Vars[se][\"cglf\"] @ sol.a\n",
    "        cla.PSD_consistent_rss(resp, *get_xyr(), freq, forcepsd, drmres, case, i)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b638743f-a407-42f7-866f-e39fe60efe4a",
   "metadata": {},
   "source": [
    "\n",
    "Miscellaneous notes regarding the \"prepare_4_cla.py\" file:\n",
    "\n",
    "- The dynamic uncertainty factor is set to 1.25\n",
    "- The SRS (shock response spectrum) is computed for some rows of some categories:\n",
    "  - Q = 10 and 33\n",
    "  - Frequency range from 0.1 to 50.0 Hz with step size 0.1 Hz\n",
    "  - The SRS calculations are performed by [pyyeti.srs.srs](../modules/generated/pyyeti.srs.srs.html#pyyeti.srs.srs), [pyyeti.srs.srs_frf](../modules/generated/pyyeti.srs.srs_frf.html#pyyeti.srs.srs_frf), and [pyyeti.srs.vrs](../modules/generated/pyyeti.srs.vrs.html#pyyeti.srs.vrs) for time-domain, frequency-domain, and PSD analyses, respectively.\n",
    "- All categories are added by using locally defined functions (all named \"_\") and the [pyyeti.cla.DR_Def.addcat](../modules/edited/pyyeti.cla.DR_Def.addcat.html#pyyeti.cla.DR_Def.addcat) decorator.\n",
    "- An elastic mode only \"net_ifatm\" category is added via [pyyeti.cla.DR_Def.add_0rb](../modules/edited/pyyeti.cla.DR_Def.add_0rb.html#pyyeti.cla.DR_Def.add_0rb). The name of the category will be \"net_ifatm_0rb\" (for zero rigid-body).\n",
    "- A summary of all categories is printed to an excel file \"dr_summary.xlsx\". This is meant for visual checking and is shown below for reference.\n",
    "- Finally, the critical data is saved to \"cla_params.pgz\" via [pyyeti.ytools.save](../modules/generated/pyyeti.ytools.save.html#pyyeti.ytools.save). (Both [pyyeti.ytools.save](../modules/generated/pyyeti.ytools.save.html#pyyeti.ytools.save) and [pyyeti.ytools.load](../modules/generated/pyyeti.ytools.load.html#pyyeti.ytools.load) are imported into the \"cla\" module for convenience.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a930258-94a1-4ee1-8133-2c10fedac8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_4_cla.py\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "from pyyeti import cla, nastran, cb\n",
    "from pyyeti.nastran import op4\n",
    "\n",
    "\n",
    "def getlabels(lbl, id_dof):\n",
    "    return [\"{} {:4d}-{:1d}\".format(lbl, g, i) for g, i in id_dof]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    se = 101\n",
    "    uset, coords, bset = nastran.asm2uset(srcdir / \"outboard.asm\")\n",
    "    bset = bset.nonzero()[0]\n",
    "    dct = op4.read(srcdir / \"outboard.op4\")\n",
    "    maa = dct[\"mxx\"]\n",
    "    kaa = dct[\"kxx\"]\n",
    "    atm = dct[\"mug1\"]\n",
    "    ltm = dct[\"mef1\"]\n",
    "    pch = srcdir / \"outboard.pch\"\n",
    "\n",
    "    atm_labels = getlabels(\"Grid\", nastran.rddtipch(pch, \"tug1\"))\n",
    "    ltm_labels = getlabels(\"CBAR\", nastran.rddtipch(pch, \"tef1\"))\n",
    "    iflabels = getlabels(\"Grid\", uset.index[bset])\n",
    "\n",
    "    # setup CLA parameters:\n",
    "    mission = \"Micro Space Station\"\n",
    "\n",
    "    ref = [600.0, 150.0, 150.0]\n",
    "    g = 9806.65\n",
    "    net = cb.mk_net_drms(maa, kaa, bset, uset=uset, ref=ref, g=g)\n",
    "\n",
    "    # run cbcheck:\n",
    "    # SPEED: chk = cb.cbcheck(\n",
    "    # SPEED:     \"outboard_cbcheck.out\", maa, kaa, bset, bref=np.arange(6), uset=uset, uref=ref\n",
    "    # SPEED: )\n",
    "\n",
    "    # define some defaults for data recovery:\n",
    "    defaults = dict(\n",
    "        se=se,\n",
    "        uf_reds=(1, 1, 1.25, 1),\n",
    "        srsfrq=np.arange(0.1, 50.1, 0.1),\n",
    "        srsQs=(10, 33),\n",
    "        drfile=srcdir / \"dr_file.py\"\n",
    "    )\n",
    "\n",
    "    drdefs = cla.DR_Def(defaults)\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        name = \"scatm\"\n",
    "        desc = \"Outboard Internal Accelerations\"\n",
    "        units = \"mm/sec^2, rad/sec^2\"\n",
    "        labels = atm_labels\n",
    "        drms = {\"atm\": atm}\n",
    "        drfunc = \"Vars[se]['atm'] @ sol.a\"\n",
    "        # want translation histories and srs curves for nodes 35 & 36:\n",
    "        prog = re.compile(\" 3[56]-[123]\")\n",
    "        i = [i for i, s in enumerate(atm_labels) if prog.search(s)]\n",
    "        histpv = np.zeros(len(labels), bool)\n",
    "        histpv[i] = True\n",
    "        srspv = histpv\n",
    "        srsopts = dict(eqsine=1, ic=\"steady\")\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        name = \"scltm\"\n",
    "        desc = \"Outboard Internal Loads\"\n",
    "        units = \"mN, mN-mm\"\n",
    "        labels = ltm_labels\n",
    "        drms = {\"ltm\": ltm}\n",
    "        drfunc = \"Vars[se]['ltm'] @ sol.d\"\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        name = \"ifatm\"\n",
    "        desc = \"S/C Interface Accelerations\"\n",
    "        units = \"mm/sec^2, rad/sec^2\"\n",
    "        labels = iflabels\n",
    "        ifatm = np.eye(bset.shape[0], maa.shape[0])\n",
    "        drms = {\"ifatm\": ifatm}\n",
    "        drfunc = \"Vars[se]['ifatm'] @ sol.a\"\n",
    "        srsopts = dict(eqsine=1, ic=\"steady\")\n",
    "        histpv = \"all\"\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        name = \"ifltm\"\n",
    "        desc = \"I/F Loads\"\n",
    "        units = \"mN, mN-mm\"\n",
    "        labels = iflabels\n",
    "        ifltma = maa[bset]\n",
    "        ifltmd = kaa[bset][:, bset]\n",
    "        drms = {\"ifltma\": ifltma, \"ifltmd\": ifltmd}\n",
    "        drfunc = \"Vars[se]['ifltma'] @ sol.a + Vars[se]['ifltmd'] @ sol.d\"\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        name = \"cglf\"\n",
    "        desc = \"S/C CG Load Factors\"\n",
    "        units = \"G\"\n",
    "        labels = net.cglf_labels\n",
    "        drms = {\"cglf\": net.cglfa}\n",
    "        histpv = slice(5)\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        name = \"net_ifatm\"\n",
    "        desc = \"NET S/C Interface Accelerations\"\n",
    "        units = \"g, rad/sec^2\"\n",
    "        labels = net.ifatm_labels\n",
    "        drms = {\"net_ifatm\": net.ifatm}\n",
    "        drfunc = \"Vars[se]['net_ifatm'] @ sol.a\"\n",
    "        srsopts = dict(eqsine=1, ic=\"steady\")\n",
    "        histpv = \"all\"\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        name = \"net_ifltm\"\n",
    "        desc = \"NET I/F Loads\"\n",
    "        units = \"mN, mN-mm\"\n",
    "        labels = net.ifltm_labels\n",
    "        drms = {\"net_ifltm\": net.ifltma}\n",
    "        drfunc = \"Vars[se]['net_ifltm'] @ sol.a\"\n",
    "        srsopts = dict(eqsine=0, ic=\"steady\")\n",
    "        histpv = \"all\"\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    # add a 0rb version of the NET ifatm:\n",
    "    drdefs.add_0rb(\"net_ifatm\")\n",
    "\n",
    "    # make excel summary file for visual checking:\n",
    "    # SPEED: drdefs.excel_summary(\"dr_summary.xlsx\")\n",
    "\n",
    "    # save data to gzipped pickle file:\n",
    "    sc = dict(mission=mission, drdefs=drdefs)\n",
    "    cla.save(\"cla_params.pgz\", sc)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3287afb6-43da-49c2-afad-81ab57e90225",
   "metadata": {},
   "source": [
    "For reference, here is a screenshot of \"dr_summary.xlsx\":\n",
    "\n",
    "![dr_summary.png](clapng/dr_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de16a1",
   "metadata": {},
   "source": [
    "## Run Events\n",
    "There are 4 events run in this CLA: transfer orbit engine start (TOES), oil and water mixing experiment (OWLab), transfer orbit burn (TOBurn), and transfer orbit engine cutoff (TOECO). After these events are run, the results are summarized and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6911e-a295-4505-a51d-7af84c41aab0",
   "metadata": {},
   "source": [
    "First, for this tutorial, we'll define a small convience function to ease running each event in it's own subdirectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567cfa57-a9c0-445b-88c1-e1dacc51417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_event_dir(event):\n",
    "    os.chdir(wrkdir)\n",
    "    event_dir = Path(event)\n",
    "    event_dir.mkdir(exist_ok=True)\n",
    "    os.chdir(event_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1d52d",
   "metadata": {},
   "source": [
    "### TOES\n",
    "Outline of Transfer Orbit Engine Start run script:\n",
    "\n",
    "- Load data recovery data\n",
    "- Load Nastran data\n",
    "- Form ULVS for the outboard model (the SC)\n",
    "  - ULVS is a row partition of the system modes to the superelement external DOF (typically the b-set and q-set DOF)\n",
    "- Prepare spacecraft data recovery matrices\n",
    "- Initialize results (ext, mnc, mxc for all drms)\n",
    "- Set rfmodes. This typically defines which modes are residual-flexibility modes, but really defines which modes are to be treated statically. See [pyyeti.ode.SolveUnc](../modules/generated/pyyeti.ode.SolveUnc.html#pyyeti.ode.SolveUnc) for more information.\n",
    "- Setup modal mass, damping, and stiffness\n",
    "  - Damping is diagonal, 2% modal damping\n",
    "- Load in forcing functions\n",
    "- Form force transform\n",
    "- Do ODE pre-calcs\n",
    "- Loop over all cases, solving the ODEs and performing data recovery\n",
    "- Compute the P99/90 statistical maximum and minimum values for each item\n",
    "- Save results and create tables and plots\n",
    "  - Some screen shots of the tables and shown below for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef81e1-daa6-4bcc-862a-bc3b8b2333da",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_event_dir(\"toes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07529302-cd7b-4c2b-baa4-37aff6c6a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate event and recover responses\n",
    "import numpy as np\n",
    "from scipy.io import matlab\n",
    "from pyyeti import stats, ode, cla\n",
    "from pyyeti.nastran import n2p, op2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # event name:\n",
    "    event = \"TOES\"\n",
    "\n",
    "    # load data recovery data:\n",
    "    sc = cla.load(wrkdir / \"cla_params.pgz\")\n",
    "    cla.PrintCLAInfo(sc[\"mission\"], event)\n",
    "\n",
    "    # load nastran data:\n",
    "    nas = op2.rdnas2cam(srcdir / \"nas2cam\")\n",
    "\n",
    "    # form ulvs for some SEs:\n",
    "    SC = 101\n",
    "    n2p.addulvs(nas, SC)\n",
    "\n",
    "    # prepare spacecraft data recovery matrices\n",
    "    DR = cla.DR_Event()\n",
    "    DR.add(nas, sc[\"drdefs\"])\n",
    "\n",
    "    # initialize results (ext, mnc, mxc for all drms)\n",
    "    results = DR.prepare_results(sc[\"mission\"], event)\n",
    "\n",
    "    # set rfmodes:\n",
    "    rfmodes = nas[\"rfmodes\"][0]\n",
    "\n",
    "    # setup modal mass, damping and stiffness\n",
    "    m = None  # None means identity\n",
    "    k = nas[\"lambda\"][0]\n",
    "    assert nas[\"nrb\"] == 6\n",
    "    k[: nas[\"nrb\"]] = 0.0\n",
    "    b = 2 * 0.02 * np.sqrt(k)\n",
    "    mbk = (m, b, k)\n",
    "\n",
    "    # load in forcing functions:\n",
    "    toes = matlab.loadmat(srcdir / \"toes_ffns.mat\", squeeze_me=True, struct_as_record=False)\n",
    "\n",
    "    # form force transform:\n",
    "    T = n2p.formdrm(nas, 0, [[8, 12], [24, 13]])[0].T\n",
    "\n",
    "    # do pre-calcs and loop over all cases:\n",
    "    ts = ode.SolveUnc(*mbk, 1 / toes[\"sr\"], rf=rfmodes)\n",
    "    LC = toes[\"ffns\"].shape[0]\n",
    "    t = toes[\"t\"]\n",
    "    for j, force in enumerate(toes[\"ffns\"]):\n",
    "        print(\"Running {} case {}\".format(event, j + 1))\n",
    "        genforce = T @ ([[1], [0.1], [1], [0.1]] * force[None, :])\n",
    "        # solve equations of motion\n",
    "        sol = ts.tsolve(genforce, static_ic=1)\n",
    "        sol.t = t\n",
    "        sol = DR.apply_uf(sol, *mbk, nas[\"nrb\"], rfmodes)\n",
    "        caseid = \"{} {:2d}\".format(event, j + 1)\n",
    "        # perform data recovery:\n",
    "        results.time_data_recovery(sol, nas[\"nrb\"], caseid, DR, LC, j)\n",
    "\n",
    "    # compute P99/90 statistical extreme values:\n",
    "    results.calc_stat_ext(stats.ksingle(0.99, 0.90, LC))\n",
    "\n",
    "    # save results:\n",
    "    cla.save(\"results.pgz\", results)\n",
    "\n",
    "    # make some srs plots and tab files:\n",
    "    # SPEED: results.rpttab()\n",
    "    # SPEED: results.srs_plots()\n",
    "    # SPEED: results.resp_plots()\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aa0fd91-b209-490a-94c7-bd5f02131c68",
   "metadata": {},
   "source": [
    "For reference, here are some screenshots created by the above run:\n",
    "\n",
    "The [pyyeti.cla.DR_Results.rpttab](../modules/edited/pyyeti.cla.DR_Results.rpttab.html#pyyeti.cla.DR_Results.rpttab) routine writes tables of results. Here is a the \"net_ifatm.tab\" file (with some lines deleted for brevity). The extrema count table at the bottom shows that case 5 drove most of the \"net_ifatm\" extreme values.\n",
    "\n",
    "![toes_net_ifatm_tab.png](clapng/toes_net_ifatm_tab.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0aa59d1-a517-45b4-a675-debb97279ec2",
   "metadata": {},
   "source": [
    "The [pyyeti.cla.DR_Results.srs_plots](../modules/edited/pyyeti.cla.DR_Results.srs_plots.html#pyyeti.cla.DR_Results.srs_plots) routine plots all requested SRS curves to a file or files. Here is the first page of the \"TOES_srs.pdf\" file:\n",
    "\n",
    "![](clapng/toes_srs_pg1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ce3d246-837a-4f44-a901-20d22bb90fcd",
   "metadata": {},
   "source": [
    "The [pyyeti.cla.DR_Results.resp_plots](../modules/edited/pyyeti.cla.DR_Results.resp_plots.html#pyyeti.cla.DR_Results.resp_plots) routine plots all requested time-history curves to a file or files. Here is the first page of the \"TOES_hist.pdf\" file:\n",
    "\n",
    "![toes_hist_pg1.png](clapng/toes_hist_pg1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c73541",
   "metadata": {},
   "source": [
    "### OWLab\n",
    "Outline for oil and water mixing experiment:\n",
    "\n",
    "- Load data recovery data\n",
    "- Load Nastran data\n",
    "- Form ULVS for the outboard model (the SC)\n",
    "- Prepare spacecraft data recovery matrices\n",
    "- Initialize Results\n",
    "- Set rfmodes\n",
    "- Setup modal mass, damping, and stiffness\n",
    "  - Damping is diagonal, 2% modal damping\n",
    "- Form force transform\n",
    "- Define the PSD forces\n",
    "- Calculate the PSD responses\n",
    "- Save results and make plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f5398-daf0-4701-aeed-51008f093c09",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "We'll see two warnings from this run, one about the frequency step being too large for accuracy, and another about a division by zero.\n",
    "\n",
    "The first warning happens during the calculation of the SRS curves within the routine [pyyeti.srs.vrs](../modules/generated/pyyeti.srs.vrs.html#pyyeti.srs.vrs). For the integration frequency vector, this routine merges the frequencies from the forcing function, which range from 25 to 45 Hz by 0.5 Hz, with the frequencies at which to compute the SRS, which range from 0.1 to 50 Hz by 0.1 Hz. At the lowest frequencies then, the delta-frequency is 0.1 Hz which is larger than 0.1 / Q, so we get the warning. We could refine the SRS frequency vector in the prepare_4_cla step above to get rid of this warning. However, as noted in [pyyeti.srs.vrs](../modules/generated/pyyeti.srs.vrs.html#pyyeti.srs.vrs), the resulting SRS should be conservative and for this tutorial, this is acceptable. Additionally, in this case, we probably only care about the SRS in the 25 to 45 Hz range, which should be accurate.\n",
    "\n",
    "The second warning happens during the calculation of the apparent frequency inside the [pyyeti.cla.DR_Results.psd_data_recovery](../modules/edited/pyyeti.cla.DR_Results.psd_data_recovery.html#pyyeti.cla.DR_Results.psd_data_recovery) routine. The \"scltm\" has 4 zero rows and each of them will cause a divide-by-zero. For those rows, the \"x\" coordinate (which is normally the apparent frequency for PSDs) is set to NaN, which is perfectly fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540f849-83d2-4a00-99ae-21d00f7727a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_event_dir(\"owlab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704ef18-5cc9-4bf4-9e78-cbffb5fb38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate event and recover responses\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "\n",
    "from pyyeti import ode, cla\n",
    "from pyyeti.nastran import n2p, op2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # event name:\n",
    "    event = \"OWLab\"\n",
    "\n",
    "    # load data recovery data:\n",
    "    sc = cla.load(wrkdir / \"cla_params.pgz\")\n",
    "    cla.PrintCLAInfo(sc[\"mission\"], event)\n",
    "\n",
    "    # load nastran data:\n",
    "    nas = op2.rdnas2cam(srcdir / \"nas2cam\")\n",
    "\n",
    "    # form ulvs for some SEs:\n",
    "    SC = 101\n",
    "    n2p.addulvs(nas, SC)\n",
    "\n",
    "    # prepare spacecraft data recovery matrices\n",
    "    DR = cla.DR_Event()\n",
    "    DR.add(nas, sc[\"drdefs\"])\n",
    "\n",
    "    # initialize results (ext, mnc, mxc for all drms)\n",
    "    results = DR.prepare_results(sc[\"mission\"], event)\n",
    "\n",
    "    # set rfmodes:\n",
    "    rfmodes = nas[\"rfmodes\"][0]\n",
    "\n",
    "    # setup modal mass, damping and stiffness\n",
    "    m = None  # None means identity\n",
    "    k = nas[\"lambda\"][0]\n",
    "    assert nas[\"nrb\"] == 6\n",
    "    k[: nas[\"nrb\"]] = 0.0\n",
    "    b = 2 * 0.02 * np.sqrt(k)\n",
    "    mbk = (m, b, k)\n",
    "\n",
    "    # form force transform:\n",
    "    T = n2p.formdrm(nas, 0, [[22, 123]])[0].T\n",
    "\n",
    "    # random part:\n",
    "    freq = cla.freq3_augment(np.arange(25.0, 45.1, 0.5), nas[\"lambda\"][0])\n",
    "    rnd = [\n",
    "        np.array(\n",
    "            [\n",
    "                # freq     x      y      z\n",
    "                [1.0, 90.0, 110.0, 110.0],\n",
    "                [30.0, 90.0, 110.0, 110.0],\n",
    "                [31.0, 200.0, 400.0, 400.0],\n",
    "                [40.0, 200.0, 400.0, 400.0],\n",
    "                [41.0, 90.0, 110.0, 110.0],\n",
    "                [50.0, 90.0, 110.0, 110.0],\n",
    "            ]\n",
    "        ),\n",
    "        np.array(\n",
    "            [\n",
    "                # freq     x      y      z\n",
    "                [1.0, 90.0, 110.0, 110.0],\n",
    "                [20.0, 90.0, 110.0, 110.0],\n",
    "                [21.0, 200.0, 400.0, 400.0],\n",
    "                [30.0, 200.0, 400.0, 400.0],\n",
    "                [31.0, 90.0, 110.0, 110.0],\n",
    "                [50.0, 90.0, 110.0, 110.0],\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    fs = ode.SolveUnc(*mbk, rf=rfmodes)\n",
    "    for j, ff in enumerate(rnd):\n",
    "        caseid = \"{} {:2d}\".format(event, j + 1)\n",
    "        print(\"Running {} case {}\".format(event, j + 1))\n",
    "        F = interp.interp1d(ff[:, 0], ff[:, 1:].T, axis=1, fill_value=0.0)(freq)\n",
    "        results.solvepsd(nas, caseid, DR, fs, F, T, freq)\n",
    "        results.psd_data_recovery(caseid, DR, len(rnd), j)\n",
    "\n",
    "    # save results:\n",
    "    cla.save(\"results.pgz\", results)\n",
    "\n",
    "    # make some srs plots and tab files:\n",
    "    # SPEED: results.rpttab()\n",
    "    # SPEED: results.srs_plots(Q=10, direc=\"srs_cases\", showall=True, plot=\"semilogy\")\n",
    "    # SPEED: results.resp_plots()\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0350b7d",
   "metadata": {},
   "source": [
    "### TOBURN\n",
    "\n",
    "TOBurn is unique among the events analyzed in this tutorial because it uses a combination equation. There are two components: a \"noise\" component (solved in the PSD domain), and a steady-state thrust component (solved in the time-domain). The combination equation is simply the sum of these two components, noting that the noise component can be positive or negative.\n",
    "\n",
    "Outline for Transfer Orbit Burn:\n",
    "\n",
    "- Define a function to combine the steady state burn with the noise of the burn\n",
    "- Load data recovery data\n",
    "- Load Nastran data\n",
    "- Form ULVS for the outboard model (the SC)\n",
    "- Prepare spacecraft data recover matrices\n",
    "- Initialize results\n",
    "- Set rfmodes\n",
    "- Setup modal mass, damping, and stiffness\n",
    "  - Damping is diagonal, 2% modal damping\n",
    "- Form force transform\n",
    "- Calculate steady-state part\n",
    "- Calculate random part\n",
    "- Calculate combined results\n",
    "- Save results and Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ed05e-a68e-425b-993d-141a71b790c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_event_dir(\"toburn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd810c8-6043-4963-9f02-981f6cdf7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate event and recover responses\n",
    "import numpy as np\n",
    "import scipy.interpolate as interp\n",
    "from pyyeti import ode, cla\n",
    "from pyyeti.nastran import n2p, op2\n",
    "\n",
    "\n",
    "def toburn_combine(event, results):\n",
    "    \"\"\"\n",
    "    TOBurn combination equation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    event: string\n",
    "        Name to use for combined results; eg \"TOBurn\" (stored in, for\n",
    "        example, ``results['combined']['SC_atm'].event``)\n",
    "    results : instance of :class:`cla.DR_Results`\n",
    "        Contains 'ss' and 'noise' instants of :class:`cla.DR_Results`.\n",
    "        For example, if there is an \"atm\" category::\n",
    "\n",
    "           results['ss']['atm']\n",
    "           results['noise']['atm']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Adds the 'combined' instance of :class:`cla.DR_Results` to\n",
    "    `results`.\n",
    "\n",
    "    The combination equation is::\n",
    "\n",
    "        mx = ss + noise\n",
    "        mn = ss - noise\n",
    "    \"\"\"\n",
    "    # use form_extreme to help form the combined results:\n",
    "    results.form_extreme(ext_name=event)\n",
    "    results[\"combined\"] = results[\"extreme\"]\n",
    "    del results[\"extreme\"]\n",
    "\n",
    "    # now, just fix the \"ext\" members:\n",
    "    for cat, sns in results[\"combined\"].items():\n",
    "        sns.domain = \"combination\"\n",
    "        noise = results[\"noise\"][cat]\n",
    "        ss = results[\"ss\"][cat]\n",
    "        term = abs(noise.ext).max(axis=1)\n",
    "        sns.ext[:, 0] = ss.ext[:, 0] + term\n",
    "        sns.ext[:, 1] = ss.ext[:, 1] - term\n",
    "        sns.exttime = None\n",
    "        sns.maxcase = [\"Combination\"] * sns.ext.shape[0]\n",
    "        sns.mincase = sns.maxcase\n",
    "        # srs:\n",
    "        if getattr(sns, \"srs\", None):\n",
    "            _srs = sns.srs\n",
    "            for Q in _srs.ext:\n",
    "                _srs.ext[Q][:] = ss.srs.ext[Q] + noise.srs.ext[Q]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # event name:\n",
    "    event = \"TOBurn\"\n",
    "\n",
    "    # load data recovery data:\n",
    "    sc = cla.load(wrkdir / \"cla_params.pgz\")\n",
    "    cla.PrintCLAInfo(sc[\"mission\"], event)\n",
    "\n",
    "    # load nastran data:\n",
    "    nas = op2.rdnas2cam(srcdir / \"nas2cam\")\n",
    "\n",
    "    # form ulvs for some SEs:\n",
    "    SC = 101\n",
    "    n2p.addulvs(nas, SC)\n",
    "\n",
    "    # prepare spacecraft data recovery matrices\n",
    "    DR = cla.DR_Event()\n",
    "    DR.add(nas, sc[\"drdefs\"])\n",
    "\n",
    "    # initialize results (ext, mnc, mxc for all drms)\n",
    "    results = cla.DR_Results()\n",
    "    results[\"ss\"] = DR.prepare_results(sc[\"mission\"], event)\n",
    "    results[\"noise\"] = DR.prepare_results(sc[\"mission\"], event)\n",
    "\n",
    "    # set rfmodes:\n",
    "    rfmodes = nas[\"rfmodes\"][0]\n",
    "\n",
    "    # setup modal mass, damping and stiffness\n",
    "    m = None  # None means identity\n",
    "    k = nas[\"lambda\"][0]\n",
    "    assert nas[\"nrb\"] == 6\n",
    "    k[: nas[\"nrb\"]] = 0.0\n",
    "    b = 2 * 0.02 * np.sqrt(k)\n",
    "    mbk = (m, b, k)\n",
    "\n",
    "    # form force transform:\n",
    "    T = n2p.formdrm(nas, 0, [[8, 12], [24, 13]])[0].T\n",
    "\n",
    "    # steady state part:\n",
    "    case = \"ss\"\n",
    "    ts = ode.SolveUnc(*mbk, rf=rfmodes)\n",
    "    genforce = T @ [[7000.0], [0.0], [7000.0], [0.0]]\n",
    "    sol = ts.tsolve(genforce, static_ic=1)\n",
    "    sol = DR.apply_uf(sol, *mbk, nas[\"nrb\"], rfmodes)\n",
    "    results[case].time_data_recovery(sol, nas[\"nrb\"], case, DR, 1, 0)\n",
    "\n",
    "    # random part:\n",
    "    case = \"noise\"\n",
    "    freq = cla.freq3_augment(np.arange(5.0, 35.1, 0.5), nas[\"lambda\"][0])\n",
    "    F = interp.interp1d(\n",
    "        [1.0, 50.0],\n",
    "        [[300.0, 300.0], [30.0, 30.0], [350.0, 350.0], [35.0, 35.0]],\n",
    "        axis=1,\n",
    "        fill_value=0.0,\n",
    "    )(freq)\n",
    "\n",
    "    results[case].solvepsd(nas, case, DR, ts, F, T, freq)\n",
    "    results[case].psd_data_recovery(case, DR, 1, 0)\n",
    "\n",
    "    # combine results:\n",
    "    toburn_combine(event, results)\n",
    "\n",
    "    # save combined results:\n",
    "    cla.save(\"results.pgz\", results[\"combined\"])\n",
    "\n",
    "    # make some reports, plots:\n",
    "    # SPEED: results[\"combined\"].rpttab(excel=event.lower())\n",
    "    # SPEED: results[\"combined\"].srs_plots()\n",
    "\n",
    "    # Plot SRS for Q=10 for ss, noise and combined:\n",
    "    # SPEED: results[\"combined\"].srs_plots(Q=10, direc=\"srs_cases\", showboth=True)\n",
    "\n",
    "    # Plot PSD response curves for the noise case\n",
    "    # SPEED: results[\"noise\"].resp_plots(plot=\"semilogy\")\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22fb7584-8d5a-4970-9a2f-5429f853d8fc",
   "metadata": {},
   "source": [
    "For reference, here is the first page of the \"TOBurn_psd.pdf\" file (from [pyyeti.cla.DR_Results.resp_plots](../modules/edited/pyyeti.cla.DR_Results.resp_plots.html#pyyeti.cla.DR_Results.resp_plots)):\n",
    "\n",
    "![toburn_pg1.png](clapng/toburn_pg1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad81f3",
   "metadata": {},
   "source": [
    "### TOECO\n",
    "Outline for Transfer Orbit Engine Cutoff:\n",
    "\n",
    "- Load data recovery data\n",
    "- Load nastran data\n",
    "- Form ULVS for the outboard model (the SC)\n",
    "- Prepare spacecraft data recovery matrices\n",
    "- Initialize results\n",
    "- Set rfmodes\n",
    "- Setup modal mass, damping, and stiffness\n",
    "  - Damping is diagonal, 2% modal damping\n",
    "- Load in forcing functions\n",
    "- Form force transform\n",
    "- Do pre-calcs and loop over all cases\n",
    "- While looping, solve equations of motion\n",
    "- Save results and make plots\n",
    "\n",
    "TOECO involves an acceleration recovery called \"alphajoint\". The following file \"alphajoint.py\" facilitates setting up this category:\n",
    "```\n",
    "# alphajoint.py\n",
    "\n",
    "import os\n",
    "from pyyeti import cla\n",
    "from pyyeti.nastran import n2p\n",
    "\n",
    "\n",
    "def alphajoint(sol, nas, Vars, se):\n",
    "    return Vars[se][\"alphadrm\"] @ sol.a\n",
    "\n",
    "\n",
    "def get_drdefs(nas, sc):\n",
    "    drdefs = cla.DR_Def(sc[\"drdefs\"].defaults)\n",
    "\n",
    "    @cla.DR_Def.addcat\n",
    "    def _():\n",
    "        se = 0\n",
    "        name = \"alphajoint\"\n",
    "        desc = \"Alpha-Joint Acceleration\"\n",
    "        units = \"mm/sec^2, rad/sec^2\"\n",
    "        labels = [\"Alpha-Joint {:2s}\".format(i) for i in \"X,Y,Z,RX,RY,RZ\".split(\",\")]\n",
    "        drms = {\"alphadrm\": n2p.formdrm(nas, 0, 33)[0]}\n",
    "        srsopts = dict(eqsine=1, ic=\"steady\")\n",
    "        histpv = 1  # second row\n",
    "        srspv = [1]\n",
    "        drfile = os.path.abspath(__file__)\n",
    "        drdefs.add(**locals())\n",
    "\n",
    "    return drdefs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700aaf1-f66f-4ae2-bb92-e8a15937ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_event_dir(\"toeco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbbf68-96a0-49dd-bb2e-96552b28c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate event and recover responses\n",
    "import numpy as np\n",
    "from scipy.io import matlab\n",
    "from pyyeti import stats, ode, cla\n",
    "from pyyeti.nastran import n2p, op2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(srcdir))\n",
    "import alphajoint\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # event name:\n",
    "    event = \"TOECO\"\n",
    "\n",
    "    # load data recovery data:\n",
    "    sc = cla.load(wrkdir / \"cla_params.pgz\")\n",
    "    cla.PrintCLAInfo(sc[\"mission\"], event)\n",
    "\n",
    "    # load nastran data:\n",
    "    nas = op2.rdnas2cam(srcdir / \"nas2cam\")\n",
    "\n",
    "    # form ulvs for some SEs:\n",
    "    SC = 101\n",
    "    n2p.addulvs(nas, SC)\n",
    "\n",
    "    # prepare spacecraft and alphajoint data recovery matrices\n",
    "    DR = cla.DR_Event()\n",
    "    DR.add(nas, sc[\"drdefs\"])\n",
    "    DR.add(nas, alphajoint.get_drdefs(nas, sc))\n",
    "\n",
    "    # initialize results (ext, mnc, mxc for all drms)\n",
    "    results = DR.prepare_results(sc[\"mission\"], event)\n",
    "\n",
    "    # set rfmodes:\n",
    "    rfmodes = nas[\"rfmodes\"][0]\n",
    "\n",
    "    # setup modal mass, damping and stiffness\n",
    "    m = None  # None means identity\n",
    "    k = nas[\"lambda\"][0]\n",
    "    assert nas[\"nrb\"] == 6\n",
    "    k[: nas[\"nrb\"]] = 0.0\n",
    "    b = 2 * 0.02 * np.sqrt(k)\n",
    "    mbk = (m, b, k)\n",
    "\n",
    "    # load in forcing functions:\n",
    "    toeco = matlab.loadmat(srcdir / \"toeco_ffns.mat\", squeeze_me=True, struct_as_record=False)\n",
    "\n",
    "    # form force transform:\n",
    "    T = n2p.formdrm(nas, 0, [[8, 12], [24, 13]])[0].T\n",
    "\n",
    "    # do pre-calcs and loop over all cases:\n",
    "    ts = ode.SolveUnc(*mbk, 1 / toeco[\"sr\"], rf=rfmodes)\n",
    "    LC = toeco[\"ffns\"].shape[0]\n",
    "    t = toeco[\"t\"]\n",
    "    for j, force in enumerate(toeco[\"ffns\"]):\n",
    "        print(\"Running {} case {}\".format(event, j + 1))\n",
    "        genforce = T @ ([[1], [0.1], [1], [0.1]] * force[None, :])\n",
    "        # solve equations of motion\n",
    "        sol = ts.tsolve(genforce, static_ic=1)\n",
    "        sol.t = t\n",
    "        sol = DR.apply_uf(sol, *mbk, nas[\"nrb\"], rfmodes)\n",
    "        caseid = \"{} {:2d}\".format(event, j + 1)\n",
    "        results.time_data_recovery(sol, nas[\"nrb\"], caseid, DR, LC, j)\n",
    "\n",
    "    # save results:\n",
    "    cla.save(\"results.pgz\", results)\n",
    "\n",
    "    # make some srs plots and tab files:\n",
    "    # SPEED: results.rpttab()\n",
    "    # SPEED: results.srs_plots()\n",
    "    # SPEED: results.resp_plots()\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad6a7c",
   "metadata": {},
   "source": [
    "Take the data recovery information, spacecraft model, and forcing function to apply the event and save the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b73cfa",
   "metadata": {},
   "source": [
    "## Summarize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b22be-b4d8-4eff-8d8e-805eee1b3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(wrkdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891b2b8-6052-47b7-bbe0-cf0034a6e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyyeti import cla\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    event = \"Envelope\"\n",
    "\n",
    "    # load data in desired order:\n",
    "    results = cla.DR_Results()\n",
    "    results.merge(\n",
    "        (\n",
    "            cla.load(fn)\n",
    "            for fn in [\n",
    "                \"toes/results.pgz\",\n",
    "                \"owlab/results.pgz\",\n",
    "                \"toburn/results.pgz\",\n",
    "                \"toeco/results.pgz\",\n",
    "            ]\n",
    "        ),\n",
    "        {\"OWLab\": \"O&W Lab\"},\n",
    "    )\n",
    "\n",
    "    results.strip_hists()\n",
    "    results.form_extreme(event, doappend=2)\n",
    "\n",
    "    # save overall results:\n",
    "    cla.save(\"summary_results.pgz\", results)\n",
    "\n",
    "    # write extrema reports:\n",
    "    # SPEED: results['extreme'].rpttab()\n",
    "    # SPEED: results['extreme'].rpttab(excel=event.lower())\n",
    "    # SPEED: results['extreme'].srs_plots(Q=33, showall=True)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcec952e-5989-4fe0-b3fe-c7441dc149ef",
   "metadata": {},
   "source": [
    "Here is the \"net_ifatm.tab\" file (with some lines deleted for brevity). The extrema count table at the bottom shows that TOBurn drove most of the \"net_ifatm\" extreme values.\n",
    "\n",
    "![ext_net_ifatm_tab.png](clapng/ext_net_ifatm_tab.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "529500ce-b776-4d0a-a2c2-04494d5d60bb",
   "metadata": {},
   "source": [
    "The [pyyeti.cla.DR_Results.rpttab](../modules/edited/pyyeti.cla.DR_Results.rpttab.html#pyyeti.cla.DR_Results.rpttab) routine can also write the results tables to an excel file. In that case, extrema count pie charts are included. Here are the \"scltm\" pie charts:\n",
    "\n",
    "![scltm_event_pie_chart.png](clapng/scltm_event_pie_chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06083627",
   "metadata": {},
   "source": [
    "### Grouping results:\n",
    "\n",
    "The following is a brief demonstration of working with results contained in an [pyyeti.cla.DR_Results](../modules/edited/pyyeti.cla.DR_Results.html#pyyeti.cla.DR_Results) instance.\n",
    "\n",
    "This code groups the events into time domain events and frequency domain events, and plots some SRS's for assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7e80c-fda2-4e74-8929-5c430d2af291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group results together to facilitate investigation:\n",
    "Grouped_Results = cla.DR_Results()\n",
    "\n",
    "# put these in the order you want:\n",
    "groups = [\n",
    "   ('Time Domain', ('TOES', 'TOECO')),\n",
    "   ('Freq Domain', ('O&W Lab', 'TOBurn')),\n",
    "]\n",
    "\n",
    "for key, names in groups:\n",
    "   Grouped_Results[key] = cla.DR_Results()\n",
    "   for name in names:\n",
    "       Grouped_Results[key][name] = results[name]\n",
    "\n",
    "Grouped_Results.form_extreme()\n",
    "\n",
    "# plot just time domain srs:\n",
    "# SPEED: Grouped_Results['Time Domain']['extreme'].srs_plots(\n",
    "# SPEED:    direc='timedomain_srs', Q=33, showall=True\n",
    "# SPEED: )\n",
    "\n",
    "# plot the srs of the two groups together:\n",
    "# SPEED: Grouped_Results['extreme'].srs_plots(\n",
    "# SPEED:    direc='grouped_srs', Q=33, showall=True\n",
    "# SPEED: )\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f098d97-3419-41bc-a79a-d881dc89058f",
   "metadata": {},
   "source": [
    "Here is a page from the \"grouped_srs/Envelope_srs.pdf\" file:\n",
    "\n",
    "![grouped_srs_ifatm_pg.png](clapng/grouped_srs_ifatm_pg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a2342",
   "metadata": {},
   "source": [
    "## Compare Results\n",
    "\n",
    "Compare results generated here to those from the contractor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8806e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyyeti import cla\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = cla.load(\"summary_results.pgz\")\n",
    "    lvc = pd.read_excel(srcdir / \"contractor_results.xlsx\", sheet_name=None, index_col=0)\n",
    "    # SPEED: results['extreme'].rptpct(lvc, names=(\"Ours\", \"Theirs\"), direc='compare')\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e4ce0-4319-4fe9-a80a-b4be7ec6c375",
   "metadata": {},
   "source": [
    "For each category, [pyyeti.cla.DR_Results.rptpct](../modules/edited/pyyeti.cla.DR_Results.rptpct.html#pyyeti.cla.DR_Results.rptpct) creates three files in the \"compare\" subdirectory: a *.cmp file, a *.cmp.histogram.png file, and a *.cmp.magpct.png file. Examples from the \"net_ifatm\" category follow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9169ede0-4958-46c2-98a5-bc9e0a256c64",
   "metadata": {},
   "source": [
    "Here is a the top of the \"net_ifatm.cmp\" file. The table at the top has the detailed comparison of maximums, minimums, and absolute-maximums. There are accompanying comparison histogram counts with statistics for each of these at the bottom (here, for brevity, only the maximums histogram data is shown). All \"net_ifatm\" maximums are within 3%, and 75% of maximums are within 1%.\n",
    "\n",
    "![cmp_net_ifatm_tab.png](clapng/cmp_net_ifatm_tab.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3172de46-663b-41e5-9c4a-4a52ca458e86",
   "metadata": {},
   "source": [
    "Here is the \"net_ifatm.cmp.histogram.png\" file which shows the histogram data in a bar plot format. Bars within 5% are shown in blue, bars from 5 to 10% are purple, and bars above 10% are red. \n",
    "\n",
    "![net_ifatm.cmp.histogram.png](clapng/net_ifatm.cmp.histogram.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0053b22-c473-4bb5-a448-cd2ac02a303d",
   "metadata": {},
   "source": [
    "Here is the \"net_ifatm.cmp.magpct.png\" file which is a scatter plot showing the comparisons of each data point versus the magnitude of \"Theirs\". It uses the same color scheme as listed for the histogram data in a bar plot format. This plot gives a quick view of how the comparison looks over the range of small numbers to large numbers.\n",
    "\n",
    "![net_ifatm.cmp.magpct.png](clapng/net_ifatm.cmp.magpct.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ea2f7a8-85d0-4c44-8207-30482b45f7a4",
   "metadata": {},
   "source": [
    "Since the above \"magpct\" plot is not that interesting, here is the \"scltm.cmp.magpct.png\" file. The shaded out areas are for values smaller than the filter (which was left at the default +/- 1e-6 and shown by the dashed vertical lines), so our focus should be on the white, \"Filtered region\". We can quickly see that there are values greater than 1000 that are off by more than 10%. More investigation would be needed to disposition these items. The specific rows can be determined from looking at the \"scltm.cmp\" file. In this case, all these differences were for CBAR bending moments and the only difference in the two sets of results is the version of Nastran used. (A deeper cause was not sought.)\n",
    "\n",
    "![scltm.cmp.magpct.png](clapng/scltm.cmp.magpct.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfee90-2de5-453b-8dc0-b0c80c0f3de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
